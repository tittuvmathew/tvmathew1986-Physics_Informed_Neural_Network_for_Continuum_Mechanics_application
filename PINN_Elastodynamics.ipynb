{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PINN_Elastodynamics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hnub4-mW86R",
        "colab_type": "code",
        "outputId": "cd6bdd7b-d9c4-4644-ff0f-e1166cec2efa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.16.5)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.7)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu) (41.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu) (0.15.6)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzHOetcHW-Cn",
        "colab_type": "code",
        "outputId": "71541b21-1d3a-4c92-be8c-5ece747babb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "    # MAIN PINN Tensorflow python code \n",
        "    # Author : Tittu Varghese Mathew, in collaboration with Sundar, Hrishikesh and Pramod \n",
        "    # Date : 6th September 2019 \n",
        "    # Reference paper : An Energy Approach to the Solution of Partial Differential\n",
        "    # Equations in Computational Mechanics via Machine Learning: Concepts, Implementation and Applications\n",
        "\n",
        "    # Import the necessary packages \n",
        "    import tensorflow as tf\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import scipy.io\n",
        "    from scipy.interpolate import griddata\n",
        "    import time\n",
        "    from itertools import product, combinations\n",
        "    from mpl_toolkits.mplot3d import Axes3D\n",
        "    from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "    import matplotlib.gridspec as gridspec\n",
        "    import pylab\n",
        "    import math \n",
        "    from operator import add\n",
        "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "    # To set the random seed number to a fixed value so that \n",
        "    # every time you run the code, same random numbering will be generated \n",
        "    # for replication purposes\n",
        "    np.random.seed(1234)\n",
        "    tf.set_random_seed(1234)\n",
        "\n",
        "    class PhysicsInformedNN:\n",
        "        # Initialize the class\n",
        "        # Xcoord,Ycoord,cbnodes,layers,c11,c12,c33,DArea,Npoints,P,Nb\n",
        "        def __init__(self, layers,u0,v0,L,T,XTp,Nx, Nt, g, Tpoints, c):        \n",
        "            \n",
        "            self.layers = layers            # Bottom boundary nodes \n",
        "            self.XTp = XTp\n",
        "            # print(XTp.shape)\n",
        "            NPoints = XTp.shape[0]\n",
        "            self.x = XTp[:,0:1]\n",
        "            self.t = XTp[:,1:2]\n",
        "            \n",
        "            #self.xtensor = tf.convert_to_tensor(self.x, dtype=tf.float32)\n",
        "            #self.ttensor = tf.convert_to_tensor(self.t, dtype=tf.float32)\n",
        "            \n",
        "            self.lb = XTp.min(0)  \t\t                # Find the minimum value in all columns\n",
        "            self.ub = XTp.max(0)\t\t\t            # Find the maximum value in all columns \n",
        "            self.layers = layers        \n",
        "            self.weights, self.biases = self.initialize_NN(self.layers)          \n",
        "            self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,log_device_placement=True))              \n",
        "            self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])\n",
        "            self.t_tf = tf.placeholder(tf.float32, shape=[None, self.t.shape[1]])\n",
        "            \n",
        "            self.u, self.u_x, self.u_t, self.u_xx, self.u_tt = self.elastodynamics(self.x_tf,self.t_tf)\n",
        "            \n",
        "            # Reshape \n",
        "            self.u_reshape = tf.reshape(self.u, [Nt, Nx])\n",
        "            self.ux_reshape = tf.reshape(self.u_x, [Nt, Nx])\n",
        "            self.ut_reshape = tf.reshape(self.u_t, [Nt, Nx])\n",
        "            self.uxx_reshape = tf.reshape(self.u_xx, [Nt, Nx])\n",
        "            self.utt_reshape = tf.reshape(self.u_tt, [Nt, Nx])\n",
        "            \n",
        "            # MSE_init      : MSE at initial time  \n",
        "            u_hat_init = self.u_reshape[0,:]\n",
        "            u0_init = u0 * np.ones(Nx)\n",
        "            u0_init_tensor = tf.convert_to_tensor(u0_init, dtype=tf.float32)\n",
        "            ut_hat_init = self.ut_reshape[0,:]\n",
        "            v0_init = v0 * np.ones(Nx)\n",
        "            v0_init_tensor = tf.convert_to_tensor(v0_init, dtype=tf.float32)\n",
        "            MSE_init_part1 = tf.multiply(tf.reduce_sum(tf.math.square(tf.math.subtract(u_hat_init,u0_init_tensor))),(1/Nx))\n",
        "            MSE_init_part2 = tf.multiply(tf.reduce_sum(tf.math.square(tf.math.subtract(ut_hat_init,v0_init_tensor))),(1/Nx))\n",
        "            MSE_init = MSE_init_part1 + MSE_init_part2 \n",
        "            \n",
        "            \n",
        "            # MSE_bnd  \n",
        "            u_hat_L_t = self.u_reshape[:,-1]\n",
        "            g_L_t = g * np.ones(Nt)\n",
        "            g_L_t_tensor = tf.convert_to_tensor(g_L_t, dtype=tf.float32)\n",
        "            MSE_bnd_part2 = tf.multiply(tf.reduce_sum(tf.math.square(tf.math.subtract(u_hat_L_t,g_L_t_tensor))),(1/Nt))\n",
        "            ux_hat_0_t = self.ux_reshape[:,0]\n",
        "            u_bar = np.zeros(Nt)\n",
        "            u_bar_indx = np.nonzero(Tpoints <= 1)       # <- here, the '1' sec time is user defined  \n",
        "            indxx = u_bar_indx[0]\n",
        "            for ii in indxx: \n",
        "                u_bar[ii] = -1 * math.sin(math.pi*Tpoints[ii])\n",
        "            u_bar_tensor = tf.convert_to_tensor(u_bar, dtype=tf.float32)                \n",
        "            MSE_bnd_part1 = tf.multiply(tf.reduce_sum(tf.math.square(tf.math.subtract(ux_hat_0_t,u_bar_tensor))),(1/Nt))\n",
        "            MSE_bnd = MSE_bnd_part1 + MSE_bnd_part2            \n",
        "            \n",
        "            # MSE_resid     : MSE of residual at internal collocation points \n",
        "            uxx_red = self.uxx_reshape[1:,1:-1]\n",
        "            utt_red = self.utt_reshape[1:,1:-1]\n",
        "            Nint = (Nt-1)*(Nx-2)\n",
        "            MSE_resid = tf.multiply(tf.reduce_sum(tf.math.square(tf.math.subtract(utt_red,(c**2)*uxx_red))),(1/Nint))\n",
        "            \n",
        "            self.loss = MSE_init + MSE_bnd + MSE_resid \n",
        "            \n",
        "            self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss,method='L-BFGS-B',options={'maxiter': 50000,'maxfun': 50000,'maxcor': 50,'maxls': 50,'ftol' : 1.0 * np.finfo(float).eps})        \n",
        "            self.optimizer_Adam = tf.train.AdamOptimizer()\n",
        "            self.train_op_Adam = self.optimizer_Adam.minimize(self.loss) \n",
        "            \n",
        "            init = tf.global_variables_initializer()\n",
        "            self.sess.run(init)\n",
        "            \n",
        "        ############################################################################\n",
        "        ####### Class function definition to initialize the weights and biases #####\n",
        "        ############################################################################\n",
        "        def initialize_NN(self,layers):        \n",
        "            # Pass in the layer information \n",
        "            weights = [] \t\t       \n",
        "            biases = []        \n",
        "            num_layers = len(layers)    \t\t\n",
        "            for l in range(0,num_layers-1):\n",
        "                W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
        "                b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\t               \n",
        "                weights.append(W)\n",
        "                biases.append(b)        \t\t\t\n",
        "            # Both W and b are tf.Variables \n",
        "            return weights, biases\n",
        "        \n",
        "        ############################################################################\n",
        "        #######  Function to define the initial weights of ANN #####################\n",
        "        ############################################################################    \n",
        "        def xavier_init(self,size):\n",
        "            in_dim = size[0]\n",
        "            out_dim = size[1]        \n",
        "            xavier_stddev = np.sqrt(2.0/(in_dim + out_dim))                \n",
        "            return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
        "        \n",
        "        ########################################################################\n",
        "        ##############   Function to calculate the variational energy ##########\n",
        "        ########################################################################\n",
        "        def elastodynamics(self,x,t):\n",
        "            u = self.net_ut(x,t)             \n",
        "            u_x = tf.gradients(u,x)[0]\n",
        "            u_t = tf.gradients(u,t)[0]            \n",
        "            u_xx = tf.gradients(u_x,x)[0]\n",
        "            u_tt = tf.gradients(u_t,t)[0]                                  \n",
        "            return u , u_x , u_t, u_xx , u_tt\n",
        "               \n",
        "        ########################################################################\n",
        "        ####### Class function to impose the boundary conditions  ##############\n",
        "        ########################################################################\n",
        "        def net_ut(self,x,t):  ## <- what is vdelta  ?? \n",
        "            XT = tf.concat([x,t] ,1)     # Concatenate the 'x' and 'y' coordinates \n",
        "            u = self.neural_net(XT,self.weights,self.biases)\n",
        "            return u\n",
        "            \n",
        "        ############################################################################\n",
        "        ###########    Neural Network design #######################################\n",
        "        ############################################################################\n",
        "        def neural_net(self, X, weights, biases):\n",
        "            num_layers = len(weights) + 1\t\t   \n",
        "            H = 2.0 * (X - self.lb) / ( self.ub - self.lb) - 1.0\n",
        "            for l in range(0,num_layers-2):\n",
        "                W = weights[l]\n",
        "                b = biases[l]\n",
        "                H = tf.nn.relu(tf.add(tf.matmul(H,W),b))**2   \n",
        "            W = weights[-1]\n",
        "            b = biases[-1]\n",
        "            return tf.add(tf.matmul(H, W), b)  # Last layer consists of only linear activation\n",
        "        \n",
        "        ############################################################################\n",
        "        #########    Function call to train ANN  ###################################\n",
        "        ############################################################################\n",
        "        def train(self, nIter): \n",
        "            tf_dict = {self.x_tf: self.x, self.t_tf: self.t}        \n",
        "            start_time = time.time()        \n",
        "            for it in range(nIter):\n",
        "                self.sess.run(self.train_op_Adam,tf_dict)            \n",
        "                if it % 100 == 0:\n",
        "                    elapsed = time.time() - start_time\n",
        "                    loss_value = self.sess.run(self.loss, tf_dict)\n",
        "                    print('It: %d, Loss: %.3e, Time: %.2f' % \n",
        "                          (it, loss_value, elapsed))\n",
        "                    start_time = time.time()  \n",
        "\n",
        "            self.optimizer.minimize(self.sess,feed_dict = tf_dict,fetches = [self.loss],loss_callback = self.callback)\n",
        "\n",
        "        ############################################################################\n",
        "        ##########     Function to perform prediction   ############################\n",
        "        ############################################################################\n",
        "        def predict(self,TimePlot,Nx,Nt,Tpoints):\n",
        "            tf_dict = {self.x_tf: self.x, self.t_tf: self.t}        \n",
        "            u_star = self.sess.run(self.u, tf_dict)\n",
        "            v_star = self.sess.run(self.u_t, tf_dict)\n",
        "            \n",
        "            u_reshape = np.reshape(u_star, [Nt, Nx])\n",
        "            v_reshape = np.reshape(v_star, [Nt, Nx])\n",
        "            \n",
        "            idx1 = np.nonzero(Tpoints==TimePlot)\n",
        "            idx = idx1[0][0]\n",
        "                        \n",
        "            u_send = u_reshape[idx,:]\n",
        "            v_send = v_reshape[idx,:]\n",
        "            \n",
        "            return u_send, v_send\n",
        "        \n",
        "        def callback(self, loss):\n",
        "            print('Loss: %.3e' % (loss))\n",
        "\n",
        "    ###############################################################################        \n",
        "    #******************               MAIN file                     **************#\n",
        "    ###############################################################################\n",
        "    if __name__ == \"__main__\": \n",
        "        \n",
        "        L = 4        # Length of the domain \n",
        "        T = 2        # Total time duration \n",
        "        c = 1        # Wave propagation speed\n",
        "        u0 = 0       # Initial displacement \n",
        "        v0 = 0       # Initial velocity   \n",
        "        g = 0        # Dirichlet bc on right end of 1D domain\n",
        "        \n",
        "        # Neural network architecture \n",
        "        # 2 inputs corresponds to 'x' and 't' dimensions \n",
        "        # 1 ouput corresponds to 'u' displacements\n",
        "        # 3 hidden layers each having 30 neurons\n",
        "        layers = [2, 50, 50, 50, 1]\n",
        "        Niter = 1000      # Number of iterations/epoch for training \n",
        "        \n",
        "        # Creat collocation points across the domain\n",
        "        Nx = 200;      # Number of collocation points along the spatial dimenaion\n",
        "        Nt = 200;      # Number of collocation points along the time dimension  \n",
        "        Xpoints = np.linspace(0,L,Nx)\n",
        "        Tpoints = np.linspace(0,T,Nt)\n",
        "        \n",
        "        count = 0\n",
        "        XTp = np.zeros([Nx*Nt,2])\n",
        "        \n",
        "        for i in range(0,Nt):\n",
        "            for j in range(0,Nx):\n",
        "                XTp[count][0] = XTp[count][0] + Xpoints[j]\n",
        "                XTp[count][1] = XTp[count][1] + Tpoints[i]\n",
        "                count = count + 1    \n",
        "        \n",
        "        # Create a class object of type PhysiceInformedNN\n",
        "        model = PhysicsInformedNN(layers,u0,v0,L,T,XTp,Nx, Nt,g, Tpoints, c)\n",
        "        model.train(Niter)   \t\t\n",
        "        \n",
        "        ############################################################################\n",
        "        #############    Time to plot the solution   ###############################\n",
        "        ############################################################################\n",
        "        # Prediction\n",
        "        TimePlot = 2\n",
        "        u_pred, v_pred = model.predict(TimePlot,Nx, Nt, Tpoints)\n",
        "        \n",
        "        # Plot the displacement solution at t = TimePlot \n",
        "        Xpoints = np.array(Xpoints).T\n",
        "        pylab.plot(Xpoints,u_pred,'-bo',label='Computed displacement')\n",
        "        #pylab.plot(Xpoints,v_pred,'-ro', label='Computed velcoty')\n",
        "        pylab.legend(loc='upper left')\n",
        "        #pylab.ylim(0,u1)\n",
        "        pylab.xlim(0,L)\n",
        "        pylab.show()       \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It: 0, Loss: 2.487e-01, Time: 4.86\n",
            "It: 100, Loss: 1.080e-01, Time: 5.29\n",
            "It: 200, Loss: 3.567e-02, Time: 5.20\n",
            "It: 300, Loss: 9.057e-03, Time: 5.19\n",
            "It: 400, Loss: 3.241e-03, Time: 5.20\n",
            "It: 500, Loss: 1.453e-03, Time: 5.19\n",
            "It: 600, Loss: 9.204e-04, Time: 5.19\n",
            "It: 700, Loss: 6.105e-04, Time: 5.19\n",
            "It: 800, Loss: 4.166e-04, Time: 5.21\n",
            "It: 900, Loss: 3.330e-04, Time: 5.21\n",
            "Loss: 2.545e-04\n",
            "Loss: 5.475e+00\n",
            "Loss: 2.542e-04\n",
            "Loss: 2.545e-04\n",
            "Loss: 2.539e-04\n",
            "Loss: 2.537e-04\n",
            "Loss: 2.537e-04\n",
            "Loss: 2.540e-04\n",
            "Loss: 2.537e-04\n",
            "Loss: 2.532e-04\n",
            "Loss: 2.540e-04\n",
            "Loss: 2.536e-04\n",
            "Loss: 2.532e-04\n",
            "Loss: 2.537e-04\n",
            "Loss: 2.537e-04\n",
            "Loss: 2.532e-04\n",
            "Loss: 2.536e-04\n",
            "Loss: 2.532e-04\n",
            "Loss: 2.532e-04\n",
            "Loss: 2.536e-04\n",
            "Loss: 2.532e-04\n",
            "Loss: 2.536e-04\n",
            "Loss: 2.532e-04\n",
            "Loss: 2.532e-04\n",
            "Loss: 2.532e-04\n",
            "Loss: 2.536e-04\n",
            "Loss: 2.532e-04\n",
            "Loss: 2.532e-04\n",
            "Loss: 2.532e-04\n",
            "Loss: 2.532e-04\n",
            "Loss: 2.532e-04\n",
            "Loss: 2.532e-04\n",
            "Loss: 2.542e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.545e-04\n",
            "Loss: 2.537e-04\n",
            "Loss: 2.536e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.530e-04\n",
            "Loss: 2.530e-04\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.000253\n",
            "  Number of iterations: 9\n",
            "  Number of functions evaluations: 55\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD8CAYAAACW/ATfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}